#How to use binaries
* **AirMouse**: the main program, it uses a trained pipeline to recognize hand poses and gestures and control your pointer
* **StaticGestureTrainer**: records the dataset for the hand poses and outputs a dataset file
* **ClickGestureTrainer**: records the dataset for the click gesture and outputs a dataset file
* **MergeTrainingSet**: merge different dataset for static hand poses (samples from different people) and outputs a trained pipeline. Useful if you want to train the static poses recognizer with samples from different people.

##Getting started
1. Use *StaticGestureTrainer* to record the needed samples for the 3 hand poses (MOUSE GRAB / PINCH / NULL). You can record multiple datasets in order to improve the recognition robustness.
2. Use *MergeTraningSet* to merge the previous create dataset files and train a pipeline.
3. Use *ClickGestureTrainer* to create a HMM model to detect clicks. You can train LEFT and RIGHT click gesture, you need to launch the program twice.
4. Create a **configuration** file as described in the next paragraph giving the path of the trained pipelines files created by the previous operations (leftclick-pipeline and rightclick-pipeline generated by ClickGestureTrainer and pose-pipeline by the MergeTrainingSet).
5. Use *AirMouse* (passing the configuration file) to take touchless control of the pointer.

##AirMouse
AirMouse is the main program which takes as argument a configuration file.
###Configuration
```
#The hand pose (static) pipeline
pose-pipeline = "pipelines/TrainedPipeline4";
#The left click gesture pipeline
leftclick-pipeline = "pipelines/LeftClickPipeline";
#The right click gesture pipeline
rightclick-pipeline = "pipelines/RightClickPipeline";
#The default speed factor (its max value) can be modified at runtime
base-speedfactor = 8.0;
#Threshold for the deadzone
shift-threshold = 0.05;
#Angle (in radians) to be completed before starting the scroll
circle-progress = 1.2;		#radians
#Sampling period form Leap Motion
sampling-period = 10;		#milliseconds
#Debounce time fro scrolling
scroll-debounce = 200; 		#milliseconds
#Debounce time for mouse click
click-debounce = 1000;		#milliseconds
```

###Usage
1. Ensure the Leap Motion Controller is connected and the `leapd` is running correctly (Leap IR LEDs on)
2. Launch the program: `./AirMouse config`
3. Use p/o to decrease/increase the base speed factor (higher speed factor means more speed but lower accuracy)
4. Put your hand above the device, virtually grab the mouse and move, the pointer should move following your hand
To stop the program press `q`.

##StaticGestureTrainer
The program records the dataset for the hand poses and outputs a dataset file.
It allows to test your training set before saving.

###Usage:
1. Launch the StaticGestureTrainer: `./StaticGestureTrainer`
2. Insert training set name
3. Press 0/1/2 to choose the pose you want to record (NULL/GRAB/PINCH)
4. Press `r` to start recording and `p` to pause 
5. Repeat 3-4 for the 3 hand poses
6. Press `t` to train a test pipeline
7. Press `j` to test your training set
8. If the result is good press `s` to save the training set  

The program will save a file with the filename set at the beginning. This file contains all the recorder samples and can be used to generate a trained pipeline with the *MergeTrainingSet*.

##ClickGestureTrainer
The program records the dataset for the click gesture and outputs a trained pipeline to be used in the AirMouse program.
It can be used to train both left and right click gesture.

###Usage:
The program takes 2 arguments as input: `./ClickGestureTrainer n_samples period`
* n_samples: the number of samples to record for each click
* period: length of the sampling period

For example to record 40 samples, one every 5ms, launch with arguments: `./ClickGestureTrainer 40 5`

1. Prss 0/1 to choose the gesture to train (Left click / Right click)
2. To record a new sample put you hand above the sensor and prepair to click
2. Press `n`, the program will start recording, execute the click gesture
3. Repeat 2 for at least 50 times (the more, the better)
4. Press `t` to start training the pipeline

##MergeTrainingSet
Merge different dataset for static hand poses and outputs a trained pipeline. Useful if you want to train the static poses recognizer with samples from different people. If you have only one dataset file do the same with only that file in order to produce a trained pipeline.

###Usage:
1. Put all the training set files (for static hand-poses) into a folder (for example "test")
2. Launch the program passing the folder name as argument (./*MergeTrainingSet test*)
3. It will merge all the training sets into one that will be partitioned into train (80%) e test (20%), train with the given samples and output  the GRT pipeline as "TrainedPipeline". This file can be passed to *AirMouse*.

